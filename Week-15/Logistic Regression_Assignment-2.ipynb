{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q1:-** \n",
    "### **What is the purpose of grid search cv in machine learning, and how does it work?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV is a library function in the sklearn model_selection package. It works by:-**\n",
    "### **Looping through predefined hyperparameters**\n",
    "### **Fitting the model on the training set**\n",
    "### **Creating a machine learning model for each combination of hyperparameters**\n",
    "### **Selecting the best parameters from the listed hyperparameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q2:-** \n",
    "### **Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **While grid search looks at every possible combination of hyperparameters to find the best model, random search only selects and tests a random combination of hyperparameters. This technique randomly samples from a grid of hyperparameters instead of conducting an exhaustive search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grid search:-**\n",
    "##### Tries every combination of a preset list of values for the hyperparameters. The best combination is chosen based on the cross-validation score.\n",
    "### **Randomized search:-**\n",
    "##### Tries random combinations of a range of values. The number of iterations is defined by the user.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q3:-**\n",
    "### **What is data leakage, and why is it a problem in machine learning? Provide an example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data leakage is when information from outside the training dataset is used to create a model. This additional information can allow the model to learn something that it otherwise would not know.**\n",
    "### **Data leakage is a problem in machine learning because it can cause the model to perform poorly in production. The model may perform well during training, but poorly when deployed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Here are some examples of data leakage:-**\n",
    "#### Including the true label of a dataset as a characteristic in the model\n",
    "#### Including information from the evaluation set into the training set\n",
    "#### Using random splitting instead of ensuring that all images of a patient are in the same split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q4:-** \n",
    "### **How can you prevent data leakage when building a machine learning model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Here are some ways to prevent data leakage when building a machine learning model:-**\n",
    "#### 1.Understand the dataset\n",
    "#### 2.Clean the dataset for duplicates\n",
    "#### 3.Select features with regard to target variable correlation and temporal ordering\n",
    "#### 4.Split the dataset into train, validation, and test groups\n",
    "#### 5.Normalize after splitting, but before cross validation\n",
    "#### 6.Perform k-fold cross validation\n",
    "#### 7.Set aside a validation set in addition to training and test sets\n",
    "#### 8.Apply data pre-processing separately to both data sets\n",
    "#### 9.Avoid target leakage during data preprocessing\n",
    "#### 10.Be aware of the potential for leakage from external data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q5:-** \n",
    "### **What is a confusion matrix, and what does it tell you about the performance of a classification model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the total number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q6:-** \n",
    "### **Explain the difference between precision and recall in the context of a confusion matrix.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Precision and recall are two evaluation metrics used to measure the performance of a classifier in binary and multiclass classification problems. Precision measures the accuracy of positive predictions, while recall measures the completeness of positive predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Precision = TP / (TP+FP)**\n",
    "### **Recall = TP / (TP+FN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q7:-**\n",
    "### **How can you interpret a confusion matrix to determine which types of errors your model is making?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The confusion matrix shows the number of correct predictions: true positives (TP) and true negatives (TN). It also shows the model errors: false positives (FP) are “false alarms,” and false negatives (FN) are missed cases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q8:-** \n",
    "### **What are some common metrics that can be derived from a confusion matrix, and how are they calculated?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy score=(TP+TN)/(TP+FP+FP+TN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Precision = TP / (TP+FP)**\n",
    "### **Recall = TP / (TP+FN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **F1 score=(1+1^2)x(precision x Recall)/(precision + Recall)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q9:-** \n",
    "### **What is the relationship between the accuracy of a model and the values in its confusion matrix?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A confusion matrix is a performance evaluation tool in machine learning, representing the accuracy of a classification model. It displays the number of true positives, true negatives, false positives, and false negatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q10:-**  \n",
    "### **How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Below is the process for calculating a confusion Matrix**\n",
    "#### You need a test dataset or a validation dataset with expected outcome values.\n",
    "#### Make a prediction for each row in your test dataset.\n",
    "#### From the expected outcomes and predictions count: The number of correct predictions for each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
