{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment Clustering-1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q1:-** \n",
    "### **What are the different types of clustering algorithms, and how do they differ in terms of their approach and underlying assumptions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **K-Means Clustering:-**\n",
    "### **Approach:-** \n",
    "#### **Divides data into a predefined number (k) of clusters based on the mean value of data points within each cluster.**\n",
    "### **Assumptions:-** \n",
    "#### **Assumes that clusters are spherical, equally sized, and have roughly the same density. It also assumes that data points belong to exactly one cluster.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.Hierarchical Clustering:-**\n",
    "#### **Approach:-**\n",
    "##### **Builds a tree-like hierarchy of clusters, either top-down (divisive) or bottom-up (agglomerative), by recursively merging or splitting clusters.**\n",
    "#### **Assumptions:-** \n",
    "##### **Doesn't assume any specific cluster shape or size. The hierarchy can be visualized using a dendrogram.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.DBSCAN (Density-Based Spatial Clustering of Applications with Noise):-**\n",
    "#### **Approach:-**\n",
    "##### **Clusters data points based on their density. It groups together data points that are close to each other and have a sufficient number of neighbors.**\n",
    "#### **Assumptions:-** \n",
    "##### **Doesn't assume spherical clusters and can find clusters of arbitrary shapes. It's less sensitive to outliers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q2:-**\n",
    "### **What is K-means clustering, and how does it work?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **K-means clustering is a popular unsupervised machine learning algorithm used for partitioning a dataset into a set of distinct, non-overlapping groups or clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **he main idea behind K-means clustering is to group similar data points together while minimizing the within-cluster variance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working of K-means clustering:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.Intialize some k values(centroids)**\n",
    "### **2.Point that are nearest to the centroid groupe them**\n",
    "### **3.move the centroid by calculated mean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q3:-**\n",
    "### **What are some advantages and limitations of K-means clustering compared to other clustering techniques?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advantages of k-means:-**\n",
    "#### **1.Relatively simple to implement.**\n",
    "#### **2.Scales to large data sets.**\n",
    "#### **3.Guarantees convergence.**\n",
    "#### **4.Can warm-start the positions of centroids.**\n",
    "#### **5.Easily adapts to new examples.**\n",
    "#### **6.Generalizes to clusters of different shapes and sizes, such as elliptical clusters.**\n",
    "#### **7.Choosing manually.**\n",
    "#### **8.Being dependent on initial values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Disadvantages of k-means:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.Choosing K manually.**\n",
    "#### **2.Being dependent on initial values.**\n",
    "#### **3.Clustering data of varying sizes and density.**\n",
    "#### **4.Clustering outliers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q4:-**  \n",
    "### **How do you determine the optimal number of clusters in K-means clustering, and what are some common methods for doing so?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Elbow Method in K-Means Clusterin:-**\n",
    "#### **1.Select the number of clusters for the dataset (K)**\n",
    "#### **2.Select the K number of centroids randomly from the dataset.**\n",
    "#### **3.Now we will use Euclidean distance or Manhattan distance as the metric to calculate the distance of the points from the nearest centroid and assign the points to that nearest cluster centroid, thus creating K clusters.**\n",
    "#### **4.Now we find the new centroid of the clusters thus formed.**\n",
    "#### **5.Again reassign the whole data point based on this new centroid, then repeat step 4. We will continue this for a given number of iterations until the position of the centroid doesnâ€™t change, i.e., there is no more convergence.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q5:-** \n",
    "### **What are some applications of K-means clustering in real-world scenarios, and how has it been used to solve specific problems?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **kmeans algorithm is very popular and used in a variety of applications such as market segmentation, document clustering, image segmentation and image compression**\n",
    "### **The goal usually when we undergo a cluster analysis is either: Get a meaningful intuition of the structure of the data we're dealing with.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q6:-** \n",
    "### **How do you interpret the output of a K-means clustering algorithm, and what insights can you derive from the resulting clusters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Interpreting the meaning of k-means clusters boils down to characterizing the clusters. A Parallel Coordinates Plot allows us to see how individual data points sit across all variables. By looking at how the values for each variable compare across clusters, we can get a sense of what each cluster represents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q7:-** \n",
    "### **What are some common challenges in implementing K-means clustering, and how can you address them?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ans:-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to generalize k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or outliers might get their own cluster instead of being ignored**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
